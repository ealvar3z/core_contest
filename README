NAME

hallucination-nonidentifiability â€” structural impossibility result for next-token models

SYNOPSIS

A proof that hallucination is unavoidable in next-token language models under
text-only learning, underspecified prompts, and forced emission.

DESCRIPTION

This repository contains a self-contained structural argument showing that,
when the underlying world state is non-identifiable from text and the system
must act, false factual assertions are unavoidable.

The result is independent of scale, optimization quality, or architecture.

FILES

- core_contest.org
  Primary document: definitions, assumptions, construction, proof sketch,
  spoken proof, diagram, references.

- Makefile
  Export targets for slides, HTML, and PDF.

BUILD

Requirements:
- GNU Emacs
- Org mode
- ox-reveal (slides)
- LaTeX (PDF)

Targets:

#+begin_src sh
make slides
make html
make pdf
#+end_src

SCOPE

This work does not (**yet**):
- benchmark models
- propose mitigations
- analyze architectures
- discuss alignment policy
- model human cognition

STATUS

WIP.

LICENSE

See LICENSE if present.
