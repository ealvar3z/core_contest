NAME

Hallucination-nonidentifiability: Structural Impossibility Result for Next-token Models

SYNOPSIS

A proof that hallucination is unavoidable in next-token language models under
text-only learning, underspecified prompts, and forced emission.

DESCRIPTION

This repository contains a self-contained structural argument showing that,
when the underlying world state is non-identifiable from text and the system
must act, false factual assertions are unavoidable.

The result is independent of scale, optimization quality, or architecture.

FILES

- core_contest.org (primary document)
- Makefile

BUILD

Requirements:
- GNU Emacs
- Org mode
- ox-reveal (slides)
- LaTeX (PDF)

Targets:

```
make slides
make html
make pdf
```

SCOPE

This work does not (**yet**):
- benchmark models
- propose mitigations
- analyze architectures
- discuss alignment policy
- model human cognition

LICENSE

See LICENSE if present.
